import db from '../models/index';
import natural from 'natural';
import { OpenAI } from 'openai';
import { gradeWithFastModel, checkFastGradingHealth } from './fastGradingClient';
require('dotenv').config();

// Polyfill fetch and FormData for Node.js < 18
if (typeof fetch === 'undefined' || typeof FormData === 'undefined') {
    try {
        // Try @whatwg-node/fetch first (better compatibility)
        const { fetch: whatwgFetch, FormData: WhatwgFormData, Headers: WhatwgHeaders, Request: WhatwgRequest, Response: WhatwgResponse } = require('@whatwg-node/fetch');
        global.fetch = whatwgFetch;
        global.FormData = WhatwgFormData;
        global.Headers = WhatwgHeaders;
        global.Request = WhatwgRequest;
        global.Response = WhatwgResponse;
        console.log('‚úÖ Using @whatwg-node/fetch polyfill for fetch and FormData API');
    } catch (whatwgError) {
        // Fallback to node-fetch + form-data
        try {
            const nodeFetch = require('node-fetch');
            global.fetch = nodeFetch;
            global.Headers = nodeFetch.Headers;
            global.Request = nodeFetch.Request;
            global.Response = nodeFetch.Response;
            console.log('‚úÖ Using node-fetch polyfill for fetch API');

            // Try to use FormData from @whatwg-node/fetch even if fetch failed
            try {
                const { FormData: WhatwgFormData } = require('@whatwg-node/fetch');
                global.FormData = WhatwgFormData;
                console.log('‚úÖ Using @whatwg-node/fetch FormData polyfill');
            } catch (formDataError) {
                // Last resort: use form-data package
                const FormDataPolyfill = require('form-data');
                global.FormData = FormDataPolyfill;
                console.log('‚úÖ Using form-data polyfill for FormData API');
            }
        } catch (error) {
            console.error('‚ùå Failed to load fetch/FormData polyfills.');
            console.error('   Please install: npm install @whatwg-node/fetch');
            console.error('   Or: npm install node-fetch@2 form-data');
            console.error('   Or upgrade Node.js to version 18+ which has built-in fetch and FormData');
        }
    }
}

/**
 * AI auto-grading service for test submissions
 * Hybrid approach: LLM ch·∫•m ƒëi·ªÉm ‚Üí HR xem v√† ƒëi·ªÅu ch·ªânh
 * S·ª≠ d·ª•ng LLM (LM Studio) ƒë·ªÉ ch·∫•m ƒëi·ªÉm t·ª± ƒë·ªông
 */

// LM Studio configuration
const LM_STUDIO_URL = process.env.LM_STUDIO_URL || 'http://127.0.0.1:1234';
// For 8GB RAM CPU: Use qwen2.5-1.5b-instruct (balanced) or qwen2.5-0.5b-instruct (fastest)
const LM_STUDIO_MODEL = process.env.LM_STUDIO_MODEL || 'qwen2.5-1.5b-instruct';

// Initialize OpenAI client for LM Studio
const openai = new OpenAI({
    baseURL: LM_STUDIO_URL + '/v1',
    apiKey: 'lm-studio',
    fetch: global.fetch,
});

// Optional flags
const ENABLE_LLM_RECHECK = process.env.ENABLE_LLM_RECHECK === 'true'; // ch·∫•m l·∫°i ca kh√≥ (0.4-0.6) b·∫±ng LLM
const ENABLE_LLM_COMMENT = process.env.ENABLE_LLM_COMMENT === 'true'; // sinh nh·∫≠n x√©t b·∫±ng LLM

/**
 * Parse JSON from LLM response (handle reasoning tags, markdown, etc.)
 * Supports both JSON objects and arrays
 */
function parseJSONFromResponse(responseText) {
    if (!responseText) return null;

    let cleaned = responseText.trim();

    // Remove reasoning tags
    cleaned = cleaned.replace(/<think>[\s\S]*?<\/think>/gi, '');
    cleaned = cleaned.replace(/<think>[\s\S]*?<\/redacted_reasoning>/gi, '');
    cleaned = cleaned.replace(/<reasoning>[\s\S]*?<\/reasoning>/gi, '');

    // Remove markdown code blocks
    cleaned = cleaned.replace(/```json\n?/gi, '');
    cleaned = cleaned.replace(/```\n?/g, '');

    // Remove common prefixes
    cleaned = cleaned.replace(/^Here is the JSON[:\s]*/i, '');
    cleaned = cleaned.replace(/^JSON[:\s]*/i, '');
    cleaned = cleaned.replace(/^Response[:\s]*/i, '');

    // Try to find JSON array first (for batch responses)
    const firstBracket = cleaned.indexOf('[');
    const lastBracket = cleaned.lastIndexOf(']');

    if (firstBracket !== -1 && lastBracket !== -1 && lastBracket > firstBracket) {
        let jsonString = cleaned.substring(firstBracket, lastBracket + 1);

        // Try to fix common JSON issues
        jsonString = jsonString.replace(/,(\s*[}\]])/g, '$1');
        // Fix incomplete JSON (if response was cut off)
        jsonString = jsonString.replace(/,\s*$/, ''); // Remove trailing comma
        jsonString = jsonString.replace(/,\s*\]/, ']'); // Remove comma before closing bracket

        try {
            return JSON.parse(jsonString);
        } catch (e) {
            console.warn('‚ö†Ô∏è Failed to parse JSON array');
        }
    }

    // Try to find JSON object (for single responses)
    const firstBrace = cleaned.indexOf('{');
    const lastBrace = cleaned.lastIndexOf('}');

    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {
        let jsonString = cleaned.substring(firstBrace, lastBrace + 1);

        // Try to fix common JSON issues
        jsonString = jsonString.replace(/,(\s*[}\]])/g, '$1');

        try {
            return JSON.parse(jsonString);
        } catch (e) {
            // If parsing fails, try simple regex extraction for score and comment only
            const scoreMatch = jsonString.match(/"score"\s*:\s*([0-9.]+)/);
            const commentMatch = jsonString.match(/"comment"\s*:\s*"([^"]*)"/);

            if (scoreMatch) {
                return {
                    score: parseFloat(scoreMatch[1]) || 0,
                    comment: commentMatch ? commentMatch[1] : ''
                };
            }
        }
    }

    return null;
}

/**
 * Calculate similarity using Natural NLP library
 * Fast method (50-100ms) with 60-70% accuracy
 */
const calculateSimilarityNLP = (candidateAnswer, correctAnswer) => {
    if (!candidateAnswer || !correctAnswer) return 0;

    const normalize = (str) => str.toLowerCase().trim().replace(/\s+/g, ' ');
    const candidate = normalize(candidateAnswer);
    const correct = normalize(correctAnswer);

    // Exact match
    if (candidate === correct) return 1.0;

    // Use Natural library for better similarity calculation
    // Jaro-Winkler distance (good for short strings)
    const jaroWinkler = natural.JaroWinklerDistance(candidate, correct);

    // Cosine similarity using TF-IDF (good for longer texts)
    const TfIdf = natural.TfIdf;
    const tfidf = new TfIdf();
    tfidf.addDocument(candidate);
    tfidf.addDocument(correct);

    // Calculate cosine similarity
    let cosineSimilarity = 0;
    const candidateTerms = new Set();
    const correctTerms = new Set();

    // Get terms from both documents
    tfidf.listTerms(0).forEach(item => candidateTerms.add(item.term));
    tfidf.listTerms(1).forEach(item => correctTerms.add(item.term));

    // Calculate dot product and magnitudes
    let dotProduct = 0;
    let candidateMagnitude = 0;
    let correctMagnitude = 0;

    const allTerms = new Set([...candidateTerms, ...correctTerms]);
    allTerms.forEach(term => {
        const candidateTfidf = tfidf.tfidf(term, 0);
        const correctTfidf = tfidf.tfidf(term, 1);
        dotProduct += candidateTfidf * correctTfidf;
        candidateMagnitude += candidateTfidf * candidateTfidf;
        correctMagnitude += correctTfidf * correctTfidf;
    });

    if (candidateMagnitude > 0 && correctMagnitude > 0) {
        cosineSimilarity = dotProduct / (Math.sqrt(candidateMagnitude) * Math.sqrt(correctMagnitude));
    }

    // Combine Jaro-Winkler and Cosine similarity
    // Jaro-Winkler is better for short strings, Cosine for longer texts
    const avgLength = (candidate.length + correct.length) / 2;
    let finalSimilarity;

    if (avgLength < 50) {
        // Short strings: prefer Jaro-Winkler
        finalSimilarity = jaroWinkler * 0.6 + cosineSimilarity * 0.4;
    } else {
        // Long strings: prefer Cosine
        finalSimilarity = jaroWinkler * 0.3 + cosineSimilarity * 0.7;
    }

    return Math.max(0, Math.min(1, finalSimilarity));
};

/**
 * Round score to nearest 0.5 (e.g., 7.3 -> 7.5, 7.7 -> 8.0)
 */
const roundToHalf = (score) => {
    return Math.round(score * 2) / 2;
};

/**
 * Get similarity status based on similarity value
 */
const getSimilarityStatus = (similarity) => {
    // ƒê·∫£m b·∫£o similarity = 0 (score = 0) lu√¥n hi·ªÉn th·ªã "C√≥ v·∫•n ƒë·ªÅ"
    if (similarity === 0) {
        return {
            level: 'problem',
            label: 'C√≥ v·∫•n ƒë·ªÅ',
            emoji: 'üî¥',
            color: 'red'
        };
    }
    
    if (similarity > 0.75) {
        return {
            level: 'good',
            label: 'ƒê√∫ng ph·∫ßn l·ªõn',
            emoji: 'üü¢',
            color: 'green'
        };
    } else if (similarity >= 0.50) {
        return {
            level: 'review',
            label: 'C·∫ßn xem l·∫°i',
            emoji: 'üü°',
            color: 'yellow'
        };
    } else {
        return {
            level: 'problem',
            label: 'C√≥ v·∫•n ƒë·ªÅ',
            emoji: 'üî¥',
            color: 'red'
        };
    }
};

/**
 * Build comment from score (PHA D - B∆∞·ªõc D2)
 */
const buildCommentFromScore = (score, maxScore) => {
    const ratio = maxScore > 0 ? score / maxScore : 0;
    // T·∫°o ch√∫t ƒëa d·∫°ng d·ª±a tr√™n ƒëi·ªÉm ƒë·ªÉ tr√°nh l·∫∑p l·∫°i m·ªôt c√¢u
    const pick = (arr) => arr[Math.max(0, Math.min(arr.length - 1, Math.floor((ratio * 10) % arr.length)))];

    if (ratio >= 0.9) {
        return pick([
            'ƒê√∫ng √Ω ho√†n to√†n, ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c',
            'B√†i l√†m t·ªët, n√™u ƒë·ªß √Ω tr·ªçng t√¢m',
            'N·ªôi dung ƒë·∫ßy ƒë·ªß, di·ªÖn ƒë·∫°t r√µ r√†ng'
        ]);
    } else if (ratio >= 0.7) {
        return pick([
            'ƒê√∫ng √Ω ch√≠nh, kh√° ƒë·∫ßy ƒë·ªß',
            'B√†i l√†m ƒë√∫ng h∆∞·ªõng, c√≤n thi·∫øu √≠t chi ti·∫øt',
            'N·ªôi dung ·ªïn, c·∫ßn b·ªï sung th√™m v√≠ d·ª•/chi ti·∫øt'
        ]);
    } else if (ratio >= 0.5) {
        return pick([
            'ƒê√∫ng √Ω nh∆∞ng thi·∫øu m·ªôt s·ªë chi ti·∫øt quan tr·ªçng',
            'C√≥ h∆∞·ªõng ƒë√∫ng, c·∫ßn l√†m r√µ th√™m n·ªôi dung',
            'ƒê√£ n√™u √Ω ch√≠nh nh∆∞ng c√≤n s∆° s√†i'
        ]);
    } else if (ratio >= 0.3) {
        return pick([
            'C√≥ nh·∫Øc ƒë·∫øn kh√°i ni·ªám nh∆∞ng c√≤n m∆° h·ªì, ch∆∞a r√µ r√†ng',
            'N·ªôi dung ch∆∞a r√µ, thi·∫øu li√™n k·∫øt v·ªõi ƒë√°p √°n',
            'C·∫ßn l√†m r√µ h∆°n, hi·ªán v·∫´n ch∆∞a ƒë·ªß √Ω'
        ]);
    } else {
        return pick([
            'L·∫°c ƒë·ªÅ ho·∫∑c tr·∫£ l·ªùi sai √Ω ch√≠nh',
            'Ch∆∞a ƒë√∫ng n·ªôi dung, c·∫ßn xem l·∫°i ƒë√°p √°n',
            'B√†i l√†m ch∆∞a li√™n quan ƒë·∫øn c√¢u h·ªèi'
        ]);
    }
};

/**
 * Generate comment using LLM (PHA D - B∆∞·ªõc D4 - Optional)
 */
const generateCommentWithLLM = async (questionText, correctAnswer, studentAnswer, score, maxScore) => {
    try {
        const prompt = `ƒê√¢y l√† c√¢u h·ªèi: ${questionText}
ƒê√°p √°n ƒë√∫ng: ${correctAnswer}
C√¢u tr·∫£ l·ªùi c·ªßa h·ªçc sinh: ${studentAnswer}
ƒêi·ªÉm ch·∫•m: ${score}/${maxScore}

H√£y vi·∫øt 1 nh·∫≠n x√©t ng·∫Øn (1-2 c√¢u) b·∫±ng ti·∫øng Vi·ªát, v·ª´a khen v·ª´a g√≥p √Ω.`;

        const response = await openai.chat.completions.create({
            model: LM_STUDIO_MODEL,
            messages: [
                {
                    role: 'system',
                    content: 'B·∫°n l√† gi√°o vi√™n ch·∫•m b√†i. Vi·∫øt nh·∫≠n x√©t ng·∫Øn g·ªçn, t√≠ch c·ª±c v√† c√≥ t√≠nh x√¢y d·ª±ng.'
                },
                {
                    role: 'user',
                    content: prompt
                }
            ],
            temperature: 0.7,
            max_tokens: 100
        });

        const comment = response.choices[0]?.message?.content || '';
        return comment.trim() || buildCommentFromScore(score, maxScore);

    } catch (error) {
        console.warn('‚ö†Ô∏è L·ªói khi LLM sinh nh·∫≠n x√©t, d√πng comment m·∫∑c ƒë·ªãnh:', error.message);
        return buildCommentFromScore(score, maxScore);
    }
};

// Normalize text for prompt: remove HTML, collapse spaces, trim length
const normalizeForPrompt = (text, maxLen = 35) => {
    if (!text) return '';
    return text
        .replace(/<[^>]*>/g, ' ')   // strip HTML tags
        .replace(/\s+/g, ' ')       // collapse whitespace
        .trim()
        .substring(0, maxLen);
};

/**
 * Grade a single answer using LLM (LM Studio) - OLD METHOD (kept for backward compatibility)
 * More accurate but slower (1-3s per question)
 */
const gradeWithLLM = async (candidateAnswer, correctAnswer, maxScore, questionText) => {
    try {
        // Optimize prompt for LLM (concise, clear JSON format)
        const prompt = `Ch·∫•m b√†i t·ª± lu·∫≠n. So s√°nh ƒë√°p √°n m·∫´u v√† c√¢u tr·∫£ l·ªùi.

ƒê√°p √°n: "${normalizeForPrompt(correctAnswer, 50)}"
Tr·∫£ l·ªùi: "${normalizeForPrompt(candidateAnswer, 50)}"
Max: ${maxScore}

JSON: {"score":0-${maxScore},"comment":"10-20 t·ª´"}`;

        const response = await openai.chat.completions.create({
            model: LM_STUDIO_MODEL,
            messages: [
                {
                    role: 'system',
                    content: 'Ch·∫•m b√†i theo rubric: ƒë√∫ng n·ªôi dung, ƒë·∫ßy ƒë·ªß √Ω, r√µ r√†ng. Tr·∫£ v·ªÅ JSON: {"score":n,"comment":""}'
                },
                {
                    role: 'user',
                    content: prompt
                }
            ],
                    temperature: 0,
                    top_p: 0.05, // T·ªêI ∆ØU: Gi·∫£m ƒë·ªÉ model sinh token nhanh h∆°n
                    max_tokens: 150,
            frequency_penalty: 0,
            presence_penalty: 0
        });

        const responseText = response.choices[0]?.message?.content || '';
        const gradingResult = parseJSONFromResponse(responseText);

        if (!gradingResult) {
            throw new Error('Kh√¥ng th·ªÉ parse JSON t·ª´ LLM response');
        }

        // Validate and normalize
        let score = Math.max(0, Math.min(maxScore, parseFloat(gradingResult.score) || 0));
        score = roundToHalf(score);
        const similarity = maxScore > 0 ? Math.max(0, Math.min(1, score / maxScore)) : 0;
        const status = getSimilarityStatus(similarity);

        return {
            score: score,
            similarity_ai: similarity,
            comment: (gradingResult.comment || '').substring(0, 200),
            isCorrect: similarity >= 0.7,
            confidence: Math.min(0.95, similarity + 0.1),
            similarityStatus: status
        };

    } catch (error) {
        console.error('‚ùå Error calling LLM for grading:', error.message);
        const similarity = calculateSimilarityNLP(candidateAnswer, correctAnswer);
        let score = similarity * maxScore;
        score = roundToHalf(score);
        const status = getSimilarityStatus(similarity);

        return {
            score: score,
            similarity_ai: similarity,
            comment: `LLM kh√¥ng kh·∫£ d·ª•ng, s·ª≠ d·ª•ng NLP (${(similarity * 100).toFixed(0)}%)`,
            confidence: similarity * 0.6,
            isCorrect: similarity >= 0.7,
            similarityStatus: status
        };
    }
};

/**
 * Grade multiple answers in a single batch using LLM (OPTIMIZED - 10-20x faster)
 * This is MUCH faster than grading one by one
 */
const gradeAnswersBatch = async (gradingItems) => {
    try {
        if (!gradingItems || gradingItems.length === 0) {
            return [];
        }

        // Filter out multiple choice questions (they don't need LLM)
        const essayItems = gradingItems.filter(item => item.questionType === 'tuluan');
        const multipleChoiceItems = gradingItems.filter(item => item.questionType === 'tracnghiem');

        // Handle multiple choice immediately (exact match, no LLM needed)
        const multipleChoiceResults = multipleChoiceItems.map(item => {
            const isExact = item.candidateAnswer.trim().toLowerCase() === item.correctAnswer.trim().toLowerCase();
            const similarity = isExact ? 1.0 : 0;
            return {
                index: item.index,
                score: isExact ? item.maxScore : 0,
                similarity_ai: similarity,
                isCorrect: isExact,
                confidence: 1.0,
                comment: isExact ? 'ƒê√°p √°n ch√≠nh x√°c' : 'ƒê√°p √°n sai',
                similarityStatus: getSimilarityStatus(similarity)
            };
        });

        if (essayItems.length === 0) {
            return multipleChoiceResults;
        }

        // B·ªè NLP auto-ch·∫•m: ƒë·∫©y to√†n b·ªô essayItems sang ML; LLM ch·ªâ fallback khi ML l·ªói
        const essayResults = [];
        const itemsNeedingLLM = [...essayItems];
        console.log(`üß† ƒê·∫©y ${itemsNeedingLLM.length}/${essayItems.length} c√¢u t·ª± lu·∫≠n sang ML (b·ªè NLP filter)`);

        // PHA D - B∆∞·ªõc D2: D√πng ML model thay v√¨ LLM ƒë·ªÉ ch·∫•m nhanh h∆°n
        if (itemsNeedingLLM.length > 0) {
            // Ki·ªÉm tra ML service c√≥ kh·∫£ d·ª•ng kh√¥ng
            let useMLModel = await checkFastGradingHealth();
            let mlModelSuccess = false;
            
            if (useMLModel) {
                // D√πng ML model (nhanh h∆°n)
                console.log(`üöÄ ƒêang ch·∫•m ${itemsNeedingLLM.length} c√¢u b·∫±ng ML model...`);
                const mlStartTime = Date.now();
                
                // Chu·∫©n b·ªã items g·ª≠i sang Python
                const items = itemsNeedingLLM.map((item) => ({
                    correctAnswer: item.correctAnswer || '',
                    studentAnswer: item.candidateAnswer || '',
                    maxScore: item.maxScore || 10,
                }));
                
                try {
                    const fastResults = await gradeWithFastModel(items);
                    const mlTime = Date.now() - mlStartTime;
                    console.log(`‚úÖ ML model ch·∫•m ${itemsNeedingLLM.length} c√¢u trong ${mlTime}ms (${(mlTime / 1000).toFixed(2)}s)`);
                    
                    // Validate k·∫øt qu·∫£
                    if (fastResults && fastResults.length === itemsNeedingLLM.length) {
                        // G√°n l·∫°i ƒëi·ªÉm cho t·ª´ng c√¢u (c√≥ th·ªÉ re-check b·∫±ng LLM cho ca kh√≥)
                        for (let idx = 0; idx < fastResults.length; idx++) {
                            const res = fastResults[idx];
                            const item = itemsNeedingLLM[idx];
                            let score = res.score;
                            let similarity = item.maxScore > 0 ? Math.max(0, Math.min(1, score / item.maxScore)) : 0;
                            let confidence = res.ratio || similarity;
                            let comment = buildCommentFromScore(score, item.maxScore);

                            // Re-check b·∫±ng LLM cho ca l∆∞ng ch·ª´ng
                            if (ENABLE_LLM_RECHECK && item.questionType === 'tuluan' && similarity >= 0.4 && similarity <= 0.6) {
                                try {
                                    const llmRes = await gradeWithLLM(item.candidateAnswer, item.correctAnswer, item.maxScore, item.questionText);
                                    score = llmRes.score;
                                    similarity = item.maxScore > 0 ? Math.max(0, Math.min(1, score / item.maxScore)) : 0;
                                    confidence = Math.max(confidence, similarity);
                                    comment = llmRes.comment || comment;
                                } catch (err) {
                                    console.warn(`‚ö†Ô∏è L·ªói LLM re-check c√¢u ${idx + 1}:`, err.message);
                                }
                            }

                            // Sinh nh·∫≠n x√©t b·∫±ng LLM (optional)
                            if (ENABLE_LLM_COMMENT && item.questionType === 'tuluan') {
                                try {
                                    const cmt = await generateCommentWithLLM(item.questionText, item.correctAnswer, item.candidateAnswer, score, item.maxScore);
                                    comment = cmt || comment;
                                } catch (err) {
                                    console.warn(`‚ö†Ô∏è L·ªói LLM comment c√¢u ${idx + 1}:`, err.message);
                                }
                            }

                            const status = getSimilarityStatus(similarity);
                            const isCorrect = similarity >= 0.7;
                            
                            essayResults.push({
                                index: item.index,
                                score,
                                similarity_ai: similarity,
                                isCorrect,
                                confidence,
                                comment,
                                similarityStatus: status
                            });
                        }
                        mlModelSuccess = true;
                    } else {
                        throw new Error(`ML model tr·∫£ v·ªÅ ${fastResults?.length || 0} k·∫øt qu·∫£, c·∫ßn ${itemsNeedingLLM.length}`);
                    }
                } catch (error) {
                    console.error('‚ùå L·ªói khi g·ªçi ML model, fallback v·ªÅ LLM:', error.message);
                    mlModelSuccess = false;
                }
            }
            
            // Fallback v·ªÅ LLM n·∫øu ML model kh√¥ng kh·∫£ d·ª•ng ho·∫∑c l·ªói
            if (!mlModelSuccess) {
                console.log(`üîÑ Fallback v·ªÅ LLM ƒë·ªÉ ch·∫•m ${itemsNeedingLLM.length} c√¢u...`);
                const optimalBatchSize = itemsNeedingLLM.length <= 30 ? itemsNeedingLLM.length : 30;
            const batches = [];
            for (let i = 0; i < itemsNeedingLLM.length; i += optimalBatchSize) {
                batches.push(itemsNeedingLLM.slice(i, i + optimalBatchSize));
            }

            for (let batchIndex = 0; batchIndex < batches.length; batchIndex++) {
                const batch = batches[batchIndex];

                // T·ªêI ∆ØU: Input 28 k√Ω t·ª± (v·ª´a ƒë·ªß ƒë·ªÉ hi·ªÉu, kh√¥ng qu√° d√†i)
                const prompt = `Ch·∫•m ${batch.length} c√¢u theo √ù NGHƒ®A. ƒê√∫ng √Ω: 80-100%. JSON array ƒê√öNG ${batch.length} ph·∫ßn t·ª≠:
[{"score":0-max},...]

${batch.map((item, i) => `${i + 1}|"${normalizeForPrompt(item.correctAnswer, 28)}"|"${normalizeForPrompt(item.candidateAnswer, 28)}"|${item.maxScore}`).join('\n')}`;

                const llmStartTime = Date.now();
                const response = await openai.chat.completions.create({
                    model: LM_STUDIO_MODEL,
                    messages: [
                        {
                            role: 'system',
                            content: `Ch·∫•m theo √ù NGHƒ®A. ƒê√∫ng √Ω (d√π kh√°c ch·ªØ): 80-100%. Tr·∫£ JSON array ƒê√öNG ${batch.length} ph·∫ßn t·ª≠: [{"score":0-max},...]`
                        },
                        {
                            role: 'user',
                            content: prompt
                        }
                    ],
                    temperature: 0,
                    top_p: 0.05, // T·ªêI ∆ØU: Gi·∫£m t·ª´ 0.1 ‚Üí 0.05 ƒë·ªÉ model b·ªõt do d·ª±, sinh token nhanh h∆°n
                    max_tokens: 80, // T·ªêI ∆ØU T·ªêI ƒêA: Gi·∫£m t·ª´ 100 ‚Üí 80 (ch·ªâ c·∫ßn score, kh√¥ng c·∫ßn comment)
                    frequency_penalty: 0,
                    presence_penalty: 0
                });
                const llmTime = Date.now() - llmStartTime;
                console.log(`‚è±Ô∏è LLM batch ${batchIndex + 1}/${batches.length}: ${batch.length} c√¢u - ${(llmTime / 1000).toFixed(1)}s`);

                const responseText = response.choices[0]?.message?.content || '';
                if (process.env.DEBUG_GRADING) {
                    console.log(`üìù LLM response (${responseText.length} chars): ${responseText.substring(0, 200)}`);
                }

                let gradingResults = parseJSONFromResponse(responseText);
                if (!Array.isArray(gradingResults)) {
                    if (gradingResults && typeof gradingResults === 'object') {
                        gradingResults = [gradingResults];
                    } else {
                        throw new Error('LLM kh√¥ng tr·∫£ v·ªÅ array h·ª£p l·ªá');
                    }
                }
                if (gradingResults.length !== batch.length) {
                    while (gradingResults.length < batch.length) gradingResults.push({ score: 0 });
                    gradingResults.splice(batch.length);
                }

                gradingResults.forEach((res, idx) => {
                    const item = batch[idx];
                    let score = parseFloat(res.score);
                    
                    // 1Ô∏è‚É£ N·∫øu LLM tr·∫£ v·ªÅ l·ªói ‚Üí m·ªõi fallback NLP
                    if (isNaN(score) || score < 0 || score > item.maxScore) {
                        const simNLP = calculateSimilarityNLP(item.candidateAnswer, item.correctAnswer);
                        score = simNLP * item.maxScore;
                    }
                    
                    // 2Ô∏è‚É£ S√ÄN ƒêI·ªÇM: Ch·ªâ √©p khi c√¢u tr·∫£ l·ªùi th·ª±c s·ª± c√≥ √Ω nghƒ©a (kh√¥ng ph·∫£i random text)
                    const semanticNLP = calculateSimilarityNLP(item.candidateAnswer, item.correctAnswer);
                    const candidateLen = (item.candidateAnswer || '').trim().length;
                    const correctLen = (item.correctAnswer || '').trim().length;
                    
                    // Ch·ªâ √©p s√†n n·∫øu:
                    // - NLP similarity >= 0.3 (gi·∫£m t·ª´ 0.4 ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c nhi·ªÅu c√¢u ƒë·ªìng nghƒ©a h∆°n)
                    // - C√¢u tr·∫£ l·ªùi >= 10 k√Ω t·ª± (kh√¥ng ph·∫£i random text ng·∫Øn)
                    // - C√¢u tr·∫£ l·ªùi >= 20% ƒë·ªô d√†i ƒë√°p √°n (gi·∫£m t·ª´ 30% ƒë·ªÉ linh ho·∫°t h∆°n)
                    // - LLM ch·∫•m < 50%
                    // - HO·∫∂C: C√¢u tr·∫£ l·ªùi d√†i >= 20 k√Ω t·ª± v√† LLM ch·∫•m < 30% (c√≥ th·ªÉ l√† ƒë·ªìng nghƒ©a nh∆∞ng NLP ch∆∞a b·∫Øt ƒë∆∞·ª£c)
                    if (score < item.maxScore * 0.5) {
                        if (semanticNLP >= 0.3 && 
                            candidateLen >= 10 && 
                            (correctLen === 0 || candidateLen >= correctLen * 0.2)) {
                            score = item.maxScore * 0.85; // ‚úÖ √âP 8.5 ƒêI·ªÇM
                        } else if (candidateLen >= 20 && score < item.maxScore * 0.3 && semanticNLP >= 0.2) {
                            // C√¢u d√†i nh∆∞ng LLM ch·∫•m r·∫•t th·∫•p, c√≥ th·ªÉ l√† ƒë·ªìng nghƒ©a
                            score = item.maxScore * 0.75; // ‚úÖ √âP 7.5 ƒêI·ªÇM
                        }
                    }
                    
                    score = roundToHalf(score);

                    const similarity = item.maxScore > 0 ? Math.max(0, Math.min(1, score / item.maxScore)) : 0;
                    const isCorrect = similarity >= 0.7;
                    const confidence = Math.min(0.95, similarity + 0.1);
                    const status = getSimilarityStatus(similarity);

                    // T·ªêI ∆ØU 1: Comment ƒë∆∞·ª£c generate b·∫±ng code (kh√¥ng t·ª´ LLM)
                    let comment = '';
                    if (similarity >= 0.9) comment = 'ƒê√∫ng √Ω ho√†n to√†n, ƒë·∫ßy ƒë·ªß';
                    else if (similarity >= 0.7) comment = 'ƒê√∫ng √Ω ch√≠nh, c√≤n thi·∫øu chi ti·∫øt';
                    else if (similarity >= 0.5) comment = 'ƒê√∫ng m·ªôt ph·∫ßn √Ω, thi·∫øu n·ªôi dung quan tr·ªçng';
                    else if (similarity >= 0.3) comment = 'Sai nhi·ªÅu √Ω, ch·ªâ ƒë√∫ng r·∫•t √≠t';
                    else comment = 'Kh√¥ng ƒë√∫ng √Ω ho·∫∑c kh√¥ng li√™n quan';

                    essayResults.push({
                        index: item.index,
                        score,
                        similarity_ai: similarity,
                        isCorrect,
                        confidence,
                        comment,
                        similarityStatus: status
                    });
                });
            }
            }
        }

        // Combine essay and multiple choice results, sort by original index
        const allResults = [...essayResults, ...multipleChoiceResults].sort((a, b) => a.index - b.index);

        console.log(`‚úÖ ƒê√£ ch·∫•m ${allResults.length} c√¢u h·ªèi trong batch`);

        return allResults;


    } catch (error) {
        console.error('‚ùå Error in gradeAnswersBatch:', error.message);
        // Fallback: grade individually using NLP
        console.warn('‚ö†Ô∏è Batch grading failed, using NLP fallback for all');
        return gradingItems.map((item, i) => {
            if (item.questionType === 'tracnghiem') {
                const isExact = item.candidateAnswer.trim().toLowerCase() === item.correctAnswer.trim().toLowerCase();
                return {
                    index: i,
                    score: isExact ? item.maxScore : 0,
                    similarity_ai: isExact ? 1.0 : 0,
                    isCorrect: isExact,
                    confidence: 1.0,
                    comment: isExact ? 'ƒê√°p √°n ch√≠nh x√°c' : 'ƒê√°p √°n sai',
                    similarityStatus: getSimilarityStatus(isExact ? 1.0 : 0)
                };
            } else {
                const similarity = calculateSimilarityNLP(item.candidateAnswer, item.correctAnswer);
                let score = similarity * item.maxScore;
                score = roundToHalf(score);
                return {
                    index: i,
                    score: score,
                    similarity_ai: similarity,
                    isCorrect: similarity >= 0.7,
                    confidence: similarity * 0.6,
                    comment: `NLP fallback (${(similarity * 100).toFixed(0)}%)`,
                    similarityStatus: getSimilarityStatus(similarity)
                };
            }
        });
    }
};

/**
 * Grade a single answer using Hybrid approach (AI only)
 * AI ch·∫•m ƒëi·ªÉm ‚Üí HR xem v√† ƒëi·ªÅu ch·ªânh
 */
const gradeAnswer = async (candidateAnswer, correctAnswer, maxScore, questionType, questionText = '') => {
    if (!candidateAnswer || candidateAnswer.trim() === '') {
        return {
            score: 0,
            similarity_nlp: 0,
            similarity_ai: 0,
            isCorrect: false,
            confidence: 1.0,
            comment: 'Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi',
            method: 'ai'
        };
    }

    // For multiple choice - exact match required (no need for AI)
    if (questionType === 'tracnghiem') {
        const isExact = candidateAnswer.trim().toLowerCase() === correctAnswer.trim().toLowerCase();
        const similarity = isExact ? 1.0 : 0;
        const status = getSimilarityStatus(similarity);

        return {
            score: isExact ? maxScore : 0,
            similarity_nlp: 0, // Kh√¥ng d√πng NLP
            similarity_ai: similarity,
            isCorrect: isExact,
            confidence: 1.0,
            comment: isExact ? 'ƒê√°p √°n ch√≠nh x√°c' : 'ƒê√°p √°n sai',
            method: 'exact', // Exact match, kh√¥ng c·∫ßn AI
            similarityStatus: status
        };
    }

    // For essay questions - ALWAYS use AI (Hybrid = AI ch·∫•m, HR ƒëi·ªÅu ch·ªânh)
    try {
        const aiResult = await gradeWithLLM(candidateAnswer, correctAnswer, maxScore, questionText);
        return {
            score: aiResult.score,
            similarity_nlp: 0, // Kh√¥ng d√πng NLP
            similarity_ai: aiResult.similarity_ai,
            isCorrect: aiResult.isCorrect,
            confidence: aiResult.confidence,
            comment: aiResult.comment,
            method: 'ai',
            similarityStatus: aiResult.similarityStatus
        };
    } catch (error) {
        // N·∫øu AI ho√†n to√†n fail, fallback v·ªÅ NLP (nh∆∞ng ƒë√°nh d·∫•u l√† fallback)
        console.warn('‚ö†Ô∏è AI failed, using NLP fallback:', error.message);
        const nlpSimilarity = calculateSimilarityNLP(candidateAnswer, correctAnswer);
        let score = nlpSimilarity * maxScore;
        score = roundToHalf(score); // Round to nearest 0.5
        const status = getSimilarityStatus(nlpSimilarity);

        return {
            score: score,
            similarity_nlp: nlpSimilarity,
            similarity_ai: nlpSimilarity, // D√πng NLP value cho AI field
            isCorrect: nlpSimilarity >= 0.7,
            confidence: nlpSimilarity * 0.6, // Lower confidence v√¨ l√† fallback
            comment: `AI kh√¥ng kh·∫£ d·ª•ng, s·ª≠ d·ª•ng NLP (ƒë·ªô t∆∞∆°ng ƒë·ªìng: ${(nlpSimilarity * 100).toFixed(0)}%)`,
            method: 'nlp-fallback', // ƒê√°nh d·∫•u l√† fallback
            similarityStatus: status
        };
    }
};

/**
 * Auto-grade all answers in a submission
 */
const autoGradeSubmission = async (submissionId) => {
    try {
        // Get submission with all answers and questions
        const submission = await db.TestSubmission.findOne({
            where: { id: submissionId },
            include: [
                {
                    model: db.Test,
                    as: 'Test',
                    include: [{
                        model: db.TestQuestion,
                        as: 'Questions',
                        attributes: ['id', 'Cauhoi', 'Dapan', 'Loaicauhoi', 'Diem']
                    }]
                },
                {
                    model: db.TestAnswer,
                    as: 'Answers',
                    include: [{
                        model: db.TestQuestion,
                        as: 'Question',
                        attributes: ['id', 'Cauhoi', 'Dapan', 'Loaicauhoi', 'Diem']
                    }]
                }
            ]
        });

        if (!submission) {
            return {
                EM: 'Kh√¥ng t√¨m th·∫•y b√†i test!',
                EC: 1,
                DT: null
            };
        }

        if (submission.Trangthai !== 'danop' && submission.Trangthai !== 'dacham') {
            return {
                EM: 'Ch·ªâ c√≥ th·ªÉ ch·∫•m b√†i ƒë√£ n·ªôp!',
                EC: 2,
                DT: null
            };
        }

        // OPTIMIZATION: Prepare all answers for batch grading
        const gradingItems = submission.Answers.map((answer, index) => ({
            index: index,
            answerId: answer.id,
            questionId: answer.Question.id,
            questionText: answer.Question.Cauhoi || '',
            correctAnswer: answer.Question.Dapan || '',
            candidateAnswer: answer.Cautraloi || '',
            maxScore: answer.Question.Diem || 10,
            questionType: answer.Question.Loaicauhoi || 'tuluan'
        }));

        console.log(`‚ö° ƒêang ch·∫•m ${gradingItems.length} c√¢u h·ªèi b·∫±ng LLM (batch processing)...`);
        const startTime = Date.now();

        // Grade all answers in a single batch (MUCH faster)
        const batchResults = await gradeAnswersBatch(gradingItems);

        const gradingTime = Date.now() - startTime;
        console.log(`‚úÖ ƒê√£ ch·∫•m ${batchResults.length} c√¢u h·ªèi trong ${gradingTime}ms (${(gradingTime / 1000).toFixed(2)}s)`);

        // Map results back to answers and update database
        const gradedAnswers = [];
        for (let i = 0; i < submission.Answers.length; i++) {
            const answer = submission.Answers[i];
            const result = batchResults[i];

            if (!result) {
                console.warn(`‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt qu·∫£ cho c√¢u h·ªèi ${i + 1}, s·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh`);
                // Use NLP fallback for missing results
                const question = answer.Question;
                const similarity = calculateSimilarityNLP(answer.Cautraloi, question.Dapan);
                let score = similarity * question.Diem;
                score = roundToHalf(score);
                const status = getSimilarityStatus(similarity);

                await answer.update({
                    Diemdatduoc: score,
                    Dungkhong: similarity >= 0.7,
                    Phuongphap: 'nlp-fallback',
                    Dosattinhcua_nlp: similarity,
                    Dosattinhcua_ai: similarity,
                    Nhanxet: `NLP fallback (${(similarity * 100).toFixed(0)}%)`
                });

                gradedAnswers.push({
                    answerId: answer.id,
                    questionId: question.id,
                    suggestedScore: score,
                    maxScore: question.Diem,
                    similarity_nlp: similarity,
                    similarity_ai: similarity,
                    isCorrect: similarity >= 0.7,
                    confidence: similarity * 0.6,
                    method: 'nlp-fallback',
                    comment: `NLP fallback (${(similarity * 100).toFixed(0)}%)`,
                    similarityStatus: status
                });
            } else {
                // Determine method used
                const method = answer.Question.Loaicauhoi === 'tracnghiem' ? 'exact' : 'ai';

                // Update answer with AI-suggested score
                await answer.update({
                    Diemdatduoc: result.score,
                    Dungkhong: result.isCorrect,
                    Phuongphap: method,
                    Dosattinhcua_nlp: 0, // Kh√¥ng d√πng NLP trong batch mode
                    Dosattinhcua_ai: result.similarity_ai,
                    Nhanxet: result.comment || null
                });

                gradedAnswers.push({
                    answerId: answer.id,
                    questionId: answer.Question.id,
                    suggestedScore: result.score,
                    maxScore: answer.Question.Diem,
                    similarity_nlp: 0,
                    similarity_ai: result.similarity_ai,
                    isCorrect: result.isCorrect,
                    confidence: result.confidence,
                    method: method,
                    comment: result.comment,
                    similarityStatus: result.similarityStatus
                });
            }
        }

        // Calculate total suggested score
        const totalScore = gradedAnswers.reduce((sum, a) => sum + a.suggestedScore, 0);

        return {
            EM: 'AI ch·∫•m ƒëi·ªÉm th√†nh c√¥ng!',
            EC: 0,
            DT: {
                submissionId: submission.id,
                gradedAnswers: gradedAnswers,
                totalSuggestedScore: totalScore,
                totalQuestions: gradedAnswers.length
            }
        };

    } catch (error) {
        console.error('Error in autoGradeSubmission:', error);
        return {
            EM: 'C√≥ l·ªói x·∫£y ra khi AI ch·∫•m ƒëi·ªÉm!',
            EC: -1,
            DT: null
        };
    }
};

export default {
    autoGradeSubmission,
    gradeAnswer
};

