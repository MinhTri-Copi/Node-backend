import db from '../models/index';
import { Op } from 'sequelize';
import fs from 'fs';
import path from 'path';
import { OpenAI } from 'openai';
require('dotenv').config();

// Import mammoth (CommonJS module)
const mammoth = require('mammoth');

// Polyfill fetch and FormData for Node.js < 18
// Try @whatwg-node/fetch first (better compatibility), fallback to node-fetch + form-data
if (typeof fetch === 'undefined' || typeof FormData === 'undefined') {
    try {
        // Try @whatwg-node/fetch (provides both fetch and FormData)
        const { fetch: whatwgFetch, FormData: WhatwgFormData, Headers: WhatwgHeaders, Request: WhatwgRequest, Response: WhatwgResponse } = require('@whatwg-node/fetch');
        global.fetch = whatwgFetch;
        global.FormData = WhatwgFormData;
        global.Headers = WhatwgHeaders;
        global.Request = WhatwgRequest;
        global.Response = WhatwgResponse;
        console.log('‚úÖ Using @whatwg-node/fetch polyfill for fetch and FormData API');
    } catch (whatwgError) {
        // Fallback to node-fetch + form-data
        try {
            const nodeFetch = require('node-fetch');
            global.fetch = nodeFetch;
            global.Headers = nodeFetch.Headers;
            global.Request = nodeFetch.Request;
            global.Response = nodeFetch.Response;
            console.log('‚úÖ Using node-fetch polyfill for fetch API');
            
            // Try to use FormData from @whatwg-node/fetch even if fetch failed
            try {
                const { FormData: WhatwgFormData } = require('@whatwg-node/fetch');
                global.FormData = WhatwgFormData;
                console.log('‚úÖ Using @whatwg-node/fetch FormData polyfill');
            } catch (formDataError) {
                // Last resort: use form-data package
                const FormDataPolyfill = require('form-data');
                // Use form-data directly - OpenAI SDK should handle it
                global.FormData = FormDataPolyfill;
                console.log('‚úÖ Using form-data polyfill for FormData API');
            }
        } catch (error) {
            console.error('‚ùå Failed to load fetch/FormData polyfills.');
            console.error('   Please install: npm install @whatwg-node/fetch');
            console.error('   Or: npm install node-fetch@2 form-data');
            console.error('   Or upgrade Node.js to version 18+ which has built-in fetch and FormData');
        }
    }
}

// LM Studio configuration
const LM_STUDIO_URL = process.env.LM_STUDIO_URL || 'http://127.0.0.1:1234';
// For 8GB RAM CPU: Use qwen2.5-1.5b-instruct (balanced) or qwen2.5-0.5b-instruct (fastest)
const LM_STUDIO_MODEL = process.env.LM_STUDIO_MODEL || 'qwen2.5-1.5b-instruct';

// Initialize OpenAI client for LM Studio
const openai = new OpenAI({
    baseURL: LM_STUDIO_URL + '/v1',
    apiKey: 'lm-studio',
    fetch: global.fetch,
});

/**
 * Parse JSON from LLM response (handle reasoning tags, markdown, etc.)
 * Supports both JSON objects and arrays
 */
function parseJSONFromResponse(responseText) {
    if (!responseText) return null;
    
    let cleaned = responseText.trim();
    
    // Remove reasoning tags
    cleaned = cleaned.replace(/<think>[\s\S]*?<\/think>/gi, '');
    cleaned = cleaned.replace(/<think>[\s\S]*?<\/redacted_reasoning>/gi, '');
    cleaned = cleaned.replace(/<reasoning>[\s\S]*?<\/reasoning>/gi, '');
    
    // Remove markdown code blocks
    cleaned = cleaned.replace(/```json\n?/gi, '');
    cleaned = cleaned.replace(/```\n?/g, '');
    
    // Remove common prefixes
    cleaned = cleaned.replace(/^Here is the JSON[:\s]*/i, '');
    cleaned = cleaned.replace(/^JSON[:\s]*/i, '');
    cleaned = cleaned.replace(/^Response[:\s]*/i, '');
    
    // Try to find JSON array first (most common for classification)
    const firstBrace = cleaned.indexOf('[');
    const lastBrace = cleaned.lastIndexOf(']');
    
    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {
        let jsonString = cleaned.substring(firstBrace, lastBrace + 1);
        
        // Try to fix common JSON issues
        // Remove trailing commas before closing bracket
        jsonString = jsonString.replace(/,(\s*[}\]])/g, '$1');
        
        try {
            const parsed = JSON.parse(jsonString);
            if (Array.isArray(parsed)) {
                // Debug: Log parsed array length
                console.log(`  üîç Parsed array with ${parsed.length} items`);
                return parsed;
            }
        } catch (error) {
            console.warn(`  ‚ö†Ô∏è JSON parse error (array): ${error.message}`);
            console.warn(`  üìù Attempted to parse (${jsonString.length} chars): ${jsonString.substring(0, 300)}...`);
            // Try to extract valid JSON array using regex as fallback
            const arrayMatch = jsonString.match(/\[[\s\S]*\]/);
            if (arrayMatch) {
                try {
                    const fixed = arrayMatch[0].replace(/,(\s*[}\]])/g, '$1');
                    const parsed = JSON.parse(fixed);
                    console.log(`  üîç Regex fallback parsed ${parsed.length} items`);
                    return parsed;
                } catch (e) {
                    console.warn(`  ‚ö†Ô∏è Regex extract also failed: ${e.message}`);
                }
            }
        }
    }
    
    // Try to find JSON object
    const firstBraceObj = cleaned.indexOf('{');
    const lastBraceObj = cleaned.lastIndexOf('}');
    
    if (firstBraceObj !== -1 && lastBraceObj !== -1 && lastBraceObj > firstBraceObj) {
        const jsonString = cleaned.substring(firstBraceObj, lastBraceObj + 1);
        try {
            const parsed = JSON.parse(jsonString);
            // If single object, wrap in array
            if (typeof parsed === 'object' && !Array.isArray(parsed)) {
                return [parsed];
            }
            return parsed;
        } catch (error) {
            console.warn(`  ‚ö†Ô∏è JSON parse error (object): ${error.message}`);
        }
    }
    
    // Last resort: try to extract JSON from text using regex
    const jsonMatch = cleaned.match(/\[[\s\S]*\]/);
    if (jsonMatch) {
        try {
            return JSON.parse(jsonMatch[0]);
        } catch (error) {
            console.warn(`  ‚ö†Ô∏è JSON extract error: ${error.message}`);
        }
    }
    
    return null;
}

/**
 * Read and parse TXT file
 */
const parseTxtFile = async (filePath) => {
    try {
        const content = fs.readFileSync(filePath, 'utf-8');
        return content;
    } catch (error) {
        console.error('Error reading TXT file:', error);
        throw new Error('Kh√¥ng th·ªÉ ƒë·ªçc file TXT!');
    }
};

/**
 * Read and parse DOCX file
 */
const parseDocxFile = async (filePath) => {
    try {
        const result = await mammoth.extractRawText({ path: filePath });
        return result.value;
    } catch (error) {
        console.error('Error reading DOCX file:', error);
        throw new Error('Kh√¥ng th·ªÉ ƒë·ªçc file DOCX!');
    }
};

/**
 * Extract questions from content using regex patterns
 * Patterns: "C√¢u x:", "Question x", "Qx.", etc.
 */
const extractQuestionsWithRegex = (content) => {
    try {
        const questions = [];
        
        // Patterns to match question headers
        // Vietnamese: "C√¢u 1:", "C√¢u 2:", "C√¢u h·ªèi 1:", etc.
        // English: "Question 1:", "Q1.", "Q 1:", etc.
        const questionPatterns = [
            /C√¢u\s+(\d+)[:\.]\s*(.+?)(?=C√¢u\s+\d+[:\.]|C√¢u\s+h·ªèi\s+\d+[:\.]|ƒê√°p √°n|Answer|$)/gis,
            /C√¢u\s+h·ªèi\s+(\d+)[:\.]\s*(.+?)(?=C√¢u\s+h·ªèi\s+\d+[:\.]|C√¢u\s+\d+[:\.]|ƒê√°p √°n|Answer|$)/gis,
            /Question\s+(\d+)[:\.]\s*(.+?)(?=Question\s+\d+[:\.]|Answer|ƒê√°p √°n|$)/gis,
            /Q\s*(\d+)[:\.]\s*(.+?)(?=Q\s*\d+[:\.]|Answer|ƒê√°p √°n|$)/gis,
            /^(\d+)[\.\)]\s+(.+?)(?=^\d+[\.\)]|ƒê√°p √°n|Answer|$)/gims
        ];

        let allMatches = [];
        
        // Try each pattern
        for (const pattern of questionPatterns) {
            const matches = [...content.matchAll(pattern)];
            allMatches = allMatches.concat(matches.map(match => ({
                number: parseInt(match[1]) || parseInt(match[0].match(/\d+/)?.[0]) || 0,
                text: match[2] || match[0],
                fullMatch: match[0]
            })));
        }

        // Remove duplicates and sort by question number
        const uniqueMatches = Array.from(
            new Map(allMatches.map(m => [m.number, m])).values()
        ).sort((a, b) => a.number - b.number);

        // Try to extract all answers from a separate "ƒê√°p √°n" section at the end
        // Many files have format: Questions first, then "ƒê√°p √°n:" section with all answers
        const answerMap = new Map();
        
        // Find "ƒê√°p √°n" section (usually at the end) - including "ƒê√°p √°n m·∫´u:"
        const answerSectionMatch = content.match(/(?:ƒê√°p √°n\s+m·∫´u|ƒê√°p √°n|Answer|Tr·∫£ l·ªùi)[:\.]?\s*\n?([\s\S]*?)(?=\n\n\n|$)/i);
        if (answerSectionMatch) {
            const answerSection = answerSectionMatch[1];
            // Extract numbered answers: "C√¢u 1: ...", "1. ...", etc.
            const numberedAnswerPattern = /(?:C√¢u\s+(\d+)|C√¢u\s+h·ªèi\s+(\d+)|^(\d+))[\.\):]?\s*(.+?)(?=C√¢u\s+\d+|C√¢u\s+h·ªèi\s+\d+|^\d+[\.\)]|$)/gims;
            const numberedAnswers = [...answerSection.matchAll(numberedAnswerPattern)];
            for (const numAnswer of numberedAnswers) {
                const qNum = parseInt(numAnswer[1] || numAnswer[2] || numAnswer[3]);
                const answer = numAnswer[4].trim();
                if (qNum && answer && answer.length > 3) {
                    answerMap.set(qNum, answer);
                }
            }
            
            // Also handle answers without numbers (directly after "ƒê√°p √°n m·∫´u:")
            // Split by double newlines or question patterns to get individual answers
            if (numberedAnswers.length === 0) {
                // Try to split answers by double newlines or patterns
                const unnumberedAnswers = answerSection.split(/\n\n+/).filter(a => a.trim().length > 10);
                // Map first answer to first question, second to second, etc.
                unnumberedAnswers.forEach((answer, index) => {
                    const qNum = index + 1; // Start from 1
                    const cleanAnswer = answer.trim().replace(/^(ƒê√°p √°n\s+m·∫´u|ƒê√°p √°n|Answer|Tr·∫£ l·ªùi)[:\.]\s*/i, '').trim();
                    if (cleanAnswer && cleanAnswer.length > 3) {
                        answerMap.set(qNum, cleanAnswer);
                    }
                });
            }
        }

        // Extract question and answer from each match
        for (const match of uniqueMatches) {
            const text = match.text.trim();
            
            // Try to find answer patterns (including "ƒê√°p √°n m·∫´u:", "ƒê√°p √°n:", etc.)
            // QUAN TR·ªåNG: D·ª´ng tr∆∞·ªõc c√¢u h·ªèi ti·∫øp theo HO·∫∂C tr∆∞·ªõc "ƒê√°p √°n m·∫´u:" c·ªßa c√¢u ti·∫øp theo
            const answerPatterns = [
                /ƒê√°p √°n\s+m·∫´u[:\.]\s*(.+?)(?=\d+\.\s|C√¢u\s+\d+|C√¢u\s+h·ªèi\s+\d+|Question\s+\d+|Q\s*\d+|ƒê√°p √°n\s+m·∫´u|üü©|$)/gis,
                /ƒê√°p √°n[:\.]\s*(.+?)(?=\d+\.\s|C√¢u\s+\d+|C√¢u\s+h·ªèi\s+\d+|Question\s+\d+|Q\s*\d+|ƒê√°p √°n\s+m·∫´u|üü©|$)/gis,
                /Answer[:\.]\s*(.+?)(?=\d+\.\s|C√¢u\s+\d+|C√¢u\s+h·ªèi\s+\d+|Question\s+\d+|Q\s*\d+|Answer|$)/gis,
                /Tr·∫£ l·ªùi[:\.]\s*(.+?)(?=\d+\.\s|C√¢u\s+\d+|C√¢u\s+h·ªèi\s+\d+|Question\s+\d+|Q\s*\d+|Tr·∫£ l·ªùi|$)/gis
            ];

            let questionText = text;
            let answerText = '';

            // Try to extract answer
            for (const answerPattern of answerPatterns) {
                const answerMatch = text.match(answerPattern);
                if (answerMatch) {
                    questionText = text.substring(0, answerMatch.index).trim();
                    answerText = answerMatch[1].trim();
                    break;
                }
            }

            // If no answer found, try to split by common separators
            if (!answerText) {
                const separators = [
                    '\n\nƒê√°p √°n m·∫´u',
                    '\nƒê√°p √°n m·∫´u',
                    '\n\nƒê√°p √°n',
                    '\nƒê√°p √°n',
                    '\n\nAnswer',
                    '\nAnswer',
                    '\n\nTr·∫£ l·ªùi',
                    '\nTr·∫£ l·ªùi',
                    '\n\n',
                    '\n---',
                    '\n==='
                ];
                for (const sep of separators) {
                    const parts = text.split(sep);
                    if (parts.length >= 2) {
                        questionText = parts[0].trim();
                        let rawAnswer = parts.slice(1).join(sep).trim();
                        // Remove "ƒê√°p √°n m·∫´u:", "ƒê√°p √°n:", etc. prefix if exists
                        rawAnswer = rawAnswer.replace(/^(ƒê√°p √°n\s+m·∫´u|ƒê√°p √°n|Answer|Tr·∫£ l·ªùi)[:\.]\s*/i, '').trim();
                        
                        // QUAN TR·ªåNG: Ch·ªâ l·∫•y ƒë√°p √°n ƒë·∫øn khi g·∫∑p c√¢u h·ªèi ti·∫øp theo
                        // D·ª´ng tr∆∞·ªõc: s·ªë + d·∫•u ch·∫•m, "C√¢u X", "ƒê√°p √°n m·∫´u:" c·ªßa c√¢u ti·∫øp theo, section marker
                        const answerEndMatch = rawAnswer.match(/(.+?)(?=\d+\.\s|C√¢u\s+\d+|C√¢u\s+h·ªèi\s+\d+|Question\s+\d+|Q\s*\d+|ƒê√°p √°n\s+m·∫´u|üü©|$)/s);
                        answerText = answerEndMatch ? answerEndMatch[1].trim() : rawAnswer.trim();
                        
                        if (answerText) break;
                    }
                }
            }
            
            // Try to find answer in next section (if answer is after question pattern)
            // This handles cases where answer is separated by newlines from question
            if (!answerText) {
                const currentMatchIndex = content.indexOf(match.fullMatch);
                if (currentMatchIndex !== -1) {
                    const searchStart = currentMatchIndex + match.fullMatch.length;
                    // Find the next question to limit search range
                    const nextQuestionMatch = content.substring(searchStart).match(/(?:^\d+\.\s|C√¢u\s+\d+|C√¢u\s+h·ªèi\s+\d+|Question\s+\d+|Q\s*\d+)/m);
                    const searchEnd = nextQuestionMatch 
                        ? searchStart + nextQuestionMatch.index 
                        : Math.min(searchStart + 2000, content.length);
                    const nextSection = content.substring(searchStart, searchEnd);
                    
                    // Look for answer patterns in next section (including "ƒê√°p √°n m·∫´u:")
                    // D·ª´ng tr∆∞·ªõc c√¢u h·ªèi ti·∫øp theo ho·∫∑c "ƒê√°p √°n m·∫´u:" c·ªßa c√¢u ti·∫øp theo
                    const answerInNext = nextSection.match(/(?:ƒê√°p √°n\s+m·∫´u|ƒê√°p √°n|Answer|Tr·∫£ l·ªùi)[:\.]\s*(.+?)(?=\d+\.\s|C√¢u\s+\d+|C√¢u\s+h·ªèi\s+\d+|Question\s+\d+|Q\s*\d+|ƒê√°p √°n\s+m·∫´u|üü©|$)/is);
                    if (answerInNext) {
                        answerText = answerInNext[1].trim();
                        // Clean up: remove leading/trailing whitespace and newlines
                        answerText = answerText.replace(/^\s+|\s+$/g, '').replace(/\n{3,}/g, '\n\n');
                    }
                }
            }
            
            // Try to get answer from answer section map (if answers are in a separate section)
            if (!answerText && answerMap.has(match.number)) {
                answerText = answerMap.get(match.number);
            }

            // Clean up question and answer
            questionText = questionText.replace(/^C√¢u\s+\d+[:\.]\s*/i, '')
                                      .replace(/^C√¢u\s+h·ªèi\s+\d+[:\.]\s*/i, '')
                                      .replace(/^Question\s+\d+[:\.]\s*/i, '')
                                      .replace(/^Q\s*\d+[:\.]\s*/i, '')
                                      .replace(/^\d+[\.\)]\s+/, '')
                                      .trim();

            // Remove leading/trailing whitespace and newlines
            questionText = questionText.replace(/^\s+|\s+$/g, '').replace(/\n{3,}/g, '\n\n');
            answerText = answerText.replace(/^\s+|\s+$/g, '').replace(/\n{3,}/g, '\n\n');

            if (questionText && questionText.length > 5) { // Minimum question length (reduced for flexibility)
                questions.push({
                    question: questionText,
                    answer: answerText || 'Ch∆∞a c√≥ ƒë√°p √°n',
                    rawText: match.fullMatch
                });
            }
        }

        console.log(`‚úÖ ƒê√£ extract ${questions.length} c√¢u h·ªèi b·∫±ng regex`);
        
        // Debug: Log s·ªë c√¢u h·ªèi c√≥ ƒë√°p √°n
        const questionsWithAnswer = questions.filter(q => q.answer && q.answer !== 'Ch∆∞a c√≥ ƒë√°p √°n').length;
        console.log(`  üìä S·ªë c√¢u h·ªèi c√≥ ƒë√°p √°n: ${questionsWithAnswer}/${questions.length}`);
        
        return questions;
    } catch (error) {
        console.error('Error extracting questions with regex:', error);
        throw new Error('L·ªói khi parse c√¢u h·ªèi b·∫±ng regex!');
    }
};

/**
 * Classify a single question using LLM (OLD METHOD - kept for backward compatibility)
 * Returns: { loaicauhoi, chude, dodai, dokho, metadata }
 */
const classifyQuestionWithLLM = async (questionText, answerText) => {
    try {
        const prompt = `H√£y ph√¢n lo·∫°i c√¢u h·ªèi sau v√† tr·∫£ k·∫øt qu·∫£ JSON:

C√¢u h·ªèi: "${questionText}"
ƒê√°p √°n: "${answerText}"

JSON format:
{
  "loaicauhoi": "tuluan | tracnghiem",
  "chude": "t√™n ch·ªß ƒë·ªÅ (v√≠ d·ª•: OOP, Collections, Exception, Networking, etc.)",
  "dodai": "ngan | trungbinh | dai",
  "dokho": "de | trungbinh | kho",
  "metadata": ["keyword1", "keyword2", "keyword3"]
}

QUAN TR·ªåNG: Ch·ªâ tr·∫£ v·ªÅ JSON object, kh√¥ng c√≥ text n√†o kh√°c!`;

        const response = await openai.chat.completions.create({
            model: LM_STUDIO_MODEL,
            messages: [
                {
                    role: 'system',
                    content: 'B·∫°n l√† h·ªá th·ªëng ph√¢n lo·∫°i c√¢u h·ªèi. B·∫°n ch·ªâ tr·∫£ v·ªÅ JSON object, kh√¥ng c√≥ text n√†o kh√°c.'
                },
                {
                    role: 'user',
                    content: prompt
                }
            ],
            temperature: 0.3,
            max_tokens: 500
        });

        const responseText = response.choices[0]?.message?.content || '';
        const classification = parseJSONFromResponse(responseText);

        if (!classification) {
            // Default values if LLM fails
            return {
                loaicauhoi: 'tuluan',
                chude: 'Kh√°c',
                dodai: 'trungbinh',
                dokho: 'trungbinh',
                metadata: []
            };
        }

        return {
            loaicauhoi: classification.loaicauhoi === 'tracnghiem' ? 'tracnghiem' : 'tuluan',
            chude: classification.chude || 'Kh√°c',
            dodai: classification.dodai || 'trungbinh',
            dokho: classification.dokho || 'trungbinh',
            metadata: classification.metadata || []
        };
    } catch (error) {
        console.error('Error classifying question with LLM:', error);
        // Return default values on error
        return {
            loaicauhoi: 'tuluan',
            chude: 'Kh√°c',
            dodai: 'trungbinh',
            dokho: 'trungbinh',
            metadata: []
        };
    }
};

/**
 * Classify multiple questions in a single batch using LLM (OPTIMIZED FOR SPEED)
 * This is MUCH faster than classifying one by one (10-40x faster)
 * Returns: Array of { loaicauhoi, chude, dodai, dokho, metadata }
 */
const classifyQuestionsBatch = async (questions) => {
    try {
        if (!questions || questions.length === 0) {
            return [];
        }

        // OPTIMIZATION: Template prompt v·ªõi y√™u c·∫ßu r√µ r√†ng v·ªÅ format
        const prompt = `Ph√¢n lo·∫°i ${questions.length} c√¢u h·ªèi. Ch·ªâ tr·∫£ v·ªÅ JSON array v·ªõi ƒê√öNG ${questions.length} ph·∫ßn t·ª≠:

V√≠ d·ª• format:
[{"type":"tl","topic":"OOP","len":"tb","diff":"m"},{"type":"tn","topic":"Backend","len":"n","diff":"e"}]

QUAN TR·ªåNG:
- type: CH·ªåN 1 gi√° tr·ªã: "tl" HO·∫∂C "tn" (kh√¥ng d√πng "|")
- len: CH·ªåN 1 gi√° tr·ªã: "n" HO·∫∂C "tb" HO·∫∂C "d" (kh√¥ng d√πng "|")
- diff: CH·ªåN 1 gi√° tr·ªã: "e" HO·∫∂C "m" HO·∫∂C "h" (kh√¥ng d√πng "|")
- topic: t√™n ch·ªß ƒë·ªÅ ng·∫Øn g·ªçn

Danh s√°ch ${questions.length} c√¢u h·ªèi:
${questions.map((q, i) => `${i + 1}. "${q.question.substring(0, 35)}"`).join('\n')}

Tr·∫£ v·ªÅ ƒê√öNG ${questions.length} ph·∫ßn t·ª≠ JSON array. M·ªói field ch·ªâ 1 gi√° tr·ªã. Kh√¥ng th√™m text.`;

        const response = await openai.chat.completions.create({
            model: LM_STUDIO_MODEL,
            messages: [
                {
                    role: 'system',
                    content: `Ph√¢n lo·∫°i c√¢u h·ªèi. Tr·∫£ v·ªÅ JSON array v·ªõi ƒê√öNG s·ªë l∆∞·ª£ng ph·∫ßn t·ª≠ nh∆∞ y√™u c·∫ßu. Format: [{"type":"tl|tn","topic":"t√™n","len":"n|tb|d","diff":"e|m|h"}]`
                },
                {
                    role: 'user',
                    content: prompt
                }
            ],
            temperature: 0,
            top_p: 0.1,
            max_tokens: Math.max(800, questions.length * 30 + 200) // TƒÉng ƒë√°ng k·ªÉ ƒë·ªÉ ƒë·ªß cho batch l·ªõn
        });

        const responseText = response.choices[0]?.message?.content || '';
        
        // Debug: Log LLM response ƒë·ªÉ xem v·∫•n ƒë·ªÅ
        if (responseText.length > 0) {
            console.log(`  üìù LLM response (${responseText.length} chars): ${responseText.substring(0, 300)}`);
        }
        
        const classifications = parseJSONFromResponse(responseText);
        
        // Debug: Log parsed result
        if (classifications && Array.isArray(classifications)) {
            console.log(`  ‚úÖ Parsed ${classifications.length} items from LLM response`);
        } else {
            console.warn(`  ‚ö†Ô∏è Failed to parse JSON from response`);
        }

        if (!classifications || !Array.isArray(classifications)) {
            console.warn('‚ö†Ô∏è LLM kh√¥ng tr·∫£ v·ªÅ array h·ª£p l·ªá, s·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh');
            // Return default values for all questions
            return questions.map(() => ({
                loaicauhoi: 'tuluan',
                chude: 'Kh√°c',
                dodai: 'trungbinh',
                dokho: 'trungbinh',
                metadata: []
            }));
        }

        // Ensure we have the same number of classifications as questions
        if (classifications.length !== questions.length) {
            console.warn(`‚ö†Ô∏è S·ªë l∆∞·ª£ng ph√¢n lo·∫°i (${classifications.length}) kh√°c s·ªë l∆∞·ª£ng c√¢u h·ªèi (${questions.length})`);
            // Pad with default values if needed
            while (classifications.length < questions.length) {
                classifications.push({
                    type: 'tl',
                    topic: 'Kh√°c',
                    len: 'tb',
                    diff: 'm',
                    kw: []
                });
            }
            // Trim if too many
            classifications.splice(questions.length);
        }

        // OPTIMIZATION: Convert shorthand to full format (fast lookup)
        const typeMap = { 'tl': 'tuluan', 'tn': 'tracnghiem' };
        const lenMap = { 'n': 'ngan', 'tb': 'trungbinh', 'd': 'dai' };
        const diffMap = { 'e': 'de', 'm': 'trungbinh', 'h': 'kho' };

        // Normalize and return classifications
        // Fix: LLM c√≥ th·ªÉ tr·∫£ v·ªÅ "n|tb|d" - c·∫ßn l·∫•y gi√° tr·ªã ƒë·∫ßu ti√™n
        return classifications.map((c) => {
            // Fix format errors: n·∫øu c√≥ "|", l·∫•y gi√° tr·ªã ƒë·∫ßu ti√™n
            const type = (c.type || '').split('|')[0].trim();
            const len = (c.len || '').split('|')[0].trim();
            const diff = (c.diff || '').split('|')[0].trim();
            
            return {
                loaicauhoi: typeMap[type] || 'tuluan',
                chude: (c.topic || 'Kh√°c').split('|')[0].trim() || 'Kh√°c',
                dodai: lenMap[len] || 'trungbinh',
                dokho: diffMap[diff] || 'trungbinh',
                metadata: []
            };
        });
    } catch (error) {
        console.error('Error classifying questions batch with LLM:', error);
        // Return default values for all questions on error
        return questions.map(() => ({
            loaicauhoi: 'tuluan',
            chude: 'Kh√°c',
            dodai: 'trungbinh',
            dokho: 'trungbinh',
            metadata: []
        }));
    }
};

/**
 * Extract questions from content using LLM (OLD METHOD - kept for backward compatibility)
 */
const extractQuestionsWithLLM = async (content, fileName) => {
    try {
        const prompt = `
B·∫°n l√† h·ªá th·ªëng tr√≠ch xu·∫•t c√¢u h·ªèi t·ª´ t√†i li·ªáu.
ƒê·ªçc n·ªôi dung sau v√† tr√≠ch xu·∫•t T·∫§T C·∫¢ c√¢u h·ªèi c√πng ƒë√°p √°n.

N·ªôi dung t√†i li·ªáu:
${content.substring(0, 8000)} ${content.length > 8000 ? '... (n·ªôi dung b·ªã c·∫Øt)' : ''}

Y√™u c·∫ßu:
1. Tr√≠ch xu·∫•t t·∫•t c·∫£ c√¢u h·ªèi v√† ƒë√°p √°n t·ª´ t√†i li·ªáu
2. Ph√¢n lo·∫°i ch·ªß ƒë·ªÅ cho m·ªói c√¢u h·ªèi (v√≠ d·ª•: OOP, Collections, Exception, etc.)
3. X√°c ƒë·ªãnh lo·∫°i c√¢u h·ªèi: "tuluan" (t·ª± lu·∫≠n) ho·∫∑c "tracnghiem" (tr·∫Øc nghi·ªám)
4. ƒê√°nh gi√° ƒë·ªô kh√≥: "de", "trungbinh", ho·∫∑c "kho"
5. ƒê√°nh gi√° ƒë·ªô d√†i: "ngan", "trungbinh", ho·∫∑c "dai"

Tr·∫£ v·ªÅ JSON array v·ªõi format:
[
  {
    "question": "N·ªôi dung c√¢u h·ªèi?",
    "answer": "ƒê√°p √°n chu·∫©n",
    "topic": "OOP",
    "type": "tuluan",
    "difficulty": "trungbinh",
    "length": "trungbinh",
    "score": 10
  },
  ...
]

QUAN TR·ªåNG: Ch·ªâ tr·∫£ v·ªÅ JSON array, kh√¥ng c√≥ text n√†o kh√°c!
`;

        const response = await openai.chat.completions.create({
            model: LM_STUDIO_MODEL,
            messages: [
                {
                    role: 'system',
                    content: 'B·∫°n l√† h·ªá th·ªëng tr√≠ch xu·∫•t c√¢u h·ªèi t·ª´ t√†i li·ªáu. B·∫°n ch·ªâ tr·∫£ v·ªÅ JSON array, kh√¥ng c√≥ text n√†o kh√°c.'
                },
                {
                    role: 'user',
                    content: prompt
                }
            ],
            temperature: 0.3,
            max_tokens: 4000
        });

        const responseText = response.choices[0]?.message?.content || '';
        const questions = parseJSONFromResponse(responseText);

        if (!questions || !Array.isArray(questions)) {
            throw new Error('LLM kh√¥ng tr·∫£ v·ªÅ danh s√°ch c√¢u h·ªèi h·ª£p l·ªá!');
        }

        return questions;
    } catch (error) {
        console.error('Error extracting questions with LLM:', error);
        throw new Error('L·ªói khi tr√≠ch xu·∫•t c√¢u h·ªèi t·ª´ LLM: ' + error.message);
    }
};

/**
 * Upload and parse question bank file
 */
const uploadQuestionBank = async (userId, file, data) => {
    const transaction = await db.sequelize.transaction();
    
    try {
        if (!file) {
            await transaction.rollback();
            return {
                EM: 'Vui l√≤ng ch·ªçn file!',
                EC: 1,
                DT: null
            };
        }

        if (!data.Ten) {
            await transaction.rollback();
            return {
                EM: 'Vui l√≤ng nh·∫≠p t√™n b·ªô ƒë·ªÅ!',
                EC: 2,
                DT: null
            };
        }

        // Determine file type
        const ext = path.extname(file.originalname).toLowerCase();
        let fileType = 'txt';
        if (ext === '.pdf') fileType = 'pdf';
        else if (ext === '.docx') fileType = 'docx';
        else if (ext === '.doc') fileType = 'docx';
        else if (ext === '.txt') fileType = 'txt';

        // Parse file content
        let content = '';
        if (fileType === 'txt') {
            content = await parseTxtFile(file.path);
        } else if (fileType === 'docx') {
            content = await parseDocxFile(file.path);
        } else {
            await transaction.rollback();
            return {
                EM: 'Hi·ªán t·∫°i ch·ªâ h·ªó tr·ª£ file TXT v√† DOCX. PDF s·∫Ω ƒë∆∞·ª£c h·ªó tr·ª£ trong t∆∞∆°ng lai!',
                EC: 3,
                DT: null
            };
        }

        // B1: Create QuestionBank first
        const questionBank = await db.QuestionBank.create({
            Ten: data.Ten,
            Mota: data.Mota || null,
            FilePath: `/uploads/question-banks/${file.filename}`,
            FileType: fileType,
            FileName: file.originalname,
            Content: content,
            Metadata: {
                fileSize: file.size,
                parsedAt: new Date().toISOString(),
                parseMethod: 'regex'
            },
            userId: userId
        }, { transaction });

        // B2: Extract questions using regex (FAST - 0.005-0.02s)
        console.log('‚ö° ƒêang extract c√¢u h·ªèi b·∫±ng regex...');
        const startTime = Date.now();
        const extractedQuestions = extractQuestionsWithRegex(content);
        const extractTime = Date.now() - startTime;
        console.log(`‚úÖ ƒê√£ extract ${extractedQuestions.length} c√¢u h·ªèi trong ${extractTime}ms`);
        
        // Debug: Log s·ªë c√¢u h·ªèi c√≥ ƒë√°p √°n
        const questionsWithAnswer = extractedQuestions.filter(q => q.answer && q.answer !== 'Ch∆∞a c√≥ ƒë√°p √°n').length;
        console.log(`  üìä S·ªë c√¢u h·ªèi c√≥ ƒë√°p √°n: ${questionsWithAnswer}/${extractedQuestions.length}`);

        if (!extractedQuestions || extractedQuestions.length === 0) {
            await transaction.rollback();
            return {
                EM: 'Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi n√†o trong file! Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file.',
                EC: 4,
                DT: null
            };
        }

        // B3: Classify questions - use simple ONE batch approach (fastest)
        console.log(`ü§ñ ƒêang ph√¢n lo·∫°i ${extractedQuestions.length} c√¢u h·ªèi b·∫±ng LLM...`);
        const classificationStartTime = Date.now();
        
        let allClassifications = [];
        
        // STRATEGY: G·ªôp 1 batch l·ªõn = nhanh nh·∫•t (gi·∫£m overhead, model reasoning 1 l·∫ßn)
        // Batch l·ªõn = √≠t request = nhanh h∆°n t·ªïng th·ªÉ ƒë√°ng k·ªÉ
        const optimalBatchSize = extractedQuestions.length <= 30 ? extractedQuestions.length : 30; // 1 batch n·∫øu ‚â§30, t·ªëi ƒëa 30
        const batches = [];
        for (let i = 0; i < extractedQuestions.length; i += optimalBatchSize) {
            batches.push(extractedQuestions.slice(i, i + optimalBatchSize));
        }
        
        console.log(`  üì¶ Processing ${batches.length} batch(es) (${optimalBatchSize} c√¢u/batch)`);
        
        // Process batches sequentially
        for (let batchIndex = 0; batchIndex < batches.length; batchIndex++) {
            const batch = batches[batchIndex];
            const startTime = Date.now();
            try {
                const classifications = await classifyQuestionsBatch(batch);
                const duration = Date.now() - startTime;
                console.log(`  ‚úì Batch ${batchIndex + 1}/${batches.length}: ${batch.length} c√¢u - ${(duration / 1000).toFixed(1)}s`);
                allClassifications.push(...classifications);
            } catch (error) {
                console.error(`  ‚úó Batch ${batchIndex + 1} error:`, error.message);
                allClassifications.push(...batch.map(() => ({
                    loaicauhoi: 'tuluan',
                    chude: 'Kh√°c',
                    dodai: 'trungbinh',
                    dokho: 'trungbinh',
                    metadata: []
                })));
            }
        }
        
        // Merge questions with their classifications
        // QUAN TR·ªåNG: Gi·ªØ nguy√™n answer t·ª´ extractedQuestions (kh√¥ng b·ªã m·∫•t khi merge)
        const classifiedQuestions = extractedQuestions.map((q, index) => {
            const classification = allClassifications[index] || {
                loaicauhoi: 'tuluan',
                chude: 'Kh√°c',
                dodai: 'trungbinh',
                dokho: 'trungbinh',
                metadata: []
            };
            
            return {
                question: q.question || '',
                answer: q.answer || 'Ch∆∞a c√≥ ƒë√°p √°n', // ƒê·∫£m b·∫£o answer ƒë∆∞·ª£c gi·ªØ l·∫°i
                loaicauhoi: classification.loaicauhoi,
                chude: classification.chude,
                dodai: classification.dodai,
                dokho: classification.dokho,
                metadata: classification.metadata || []
            };
        });
        
        const classificationTime = Date.now() - classificationStartTime;
        console.log(`‚úÖ ƒê√£ ph√¢n lo·∫°i ${classifiedQuestions.length} c√¢u h·ªèi trong ${classificationTime}ms (${(classificationTime / 1000).toFixed(2)}s)`);

        // B4: Create QuestionBankItems with classification
        const itemsToCreate = classifiedQuestions.map((q, index) => ({
            Cauhoi: q.question || '',
            Dapan: q.answer || 'Ch∆∞a c√≥ ƒë√°p √°n',
            Chude: q.chude || 'Kh√°c',
            Loaicauhoi: q.loaicauhoi || 'tuluan',
            Diem: 10, // Default score
            Dodai: q.dodai || 'trungbinh',
            Dokho: q.dokho || 'trungbinh',
            Metadata: {
                extractedAt: new Date().toISOString(),
                originalIndex: index,
                keywords: q.metadata || [],
                extractTime: extractTime,
                classificationTime: classificationTime
            },
            questionBankId: questionBank.id
        }));

        await db.QuestionBankItem.bulkCreate(itemsToCreate, { transaction });

        // Update QuestionBank metadata with final stats
        const topics = [...new Set(classifiedQuestions.map(q => q.chude).filter(Boolean))];
        await questionBank.update({
            Metadata: {
                totalQuestions: classifiedQuestions.length,
                topics: topics,
                fileSize: file.size,
                parsedAt: new Date().toISOString(),
                parseMethod: 'regex',
                extractTime: extractTime,
                classificationTime: classificationTime,
                totalTime: extractTime + classificationTime
            }
        }, { transaction });

        await transaction.commit();

        return {
            EM: 'Upload v√† tr√≠ch xu·∫•t b·ªô ƒë·ªÅ th√†nh c√¥ng!',
            EC: 0,
            DT: {
                questionBankId: questionBank.id,
                totalQuestions: extractedQuestions.length,
                fileName: file.originalname
            }
        };

    } catch (error) {
        await transaction.rollback();
        console.error('Error in uploadQuestionBank:', error);
        return {
            EM: 'C√≥ l·ªói x·∫£y ra khi upload b·ªô ƒë·ªÅ: ' + error.message,
            EC: -1,
            DT: null
        };
    }
};

/**
 * Get all question banks for HR
 */
const getQuestionBanks = async (userId) => {
    try {
        const questionBanks = await db.QuestionBank.findAll({
            where: { userId },
            include: [{
                model: db.QuestionBankItem,
                as: 'Items',
                attributes: ['id']
            }],
            order: [['createdAt', 'DESC']]
        });

        const result = questionBanks.map(bank => ({
            id: bank.id,
            Ten: bank.Ten,
            Mota: bank.Mota,
            FileName: bank.FileName,
            FileType: bank.FileType,
            totalQuestions: bank.Items?.length || 0,
            topics: bank.Metadata?.topics || [],
            createdAt: bank.createdAt
        }));

        return {
            EM: 'L·∫•y danh s√°ch b·ªô ƒë·ªÅ th√†nh c√¥ng!',
            EC: 0,
            DT: result
        };
    } catch (error) {
        console.error('Error in getQuestionBanks:', error);
        return {
            EM: 'C√≥ l·ªói x·∫£y ra khi l·∫•y danh s√°ch b·ªô ƒë·ªÅ!',
            EC: -1,
            DT: null
        };
    }
};

/**
 * Get question bank detail with items
 */
const getQuestionBankDetail = async (userId, bankId) => {
    try {
        const questionBank = await db.QuestionBank.findOne({
            where: {
                id: bankId,
                userId: userId
            },
            include: [{
                model: db.QuestionBankItem,
                as: 'Items',
                attributes: ['id', 'Cauhoi', 'Dapan', 'Chude', 'Loaicauhoi', 'Diem', 'Dodai', 'Dokho']
            }]
        });

        if (!questionBank) {
            return {
                EM: 'Kh√¥ng t√¨m th·∫•y b·ªô ƒë·ªÅ!',
                EC: 1,
                DT: null
            };
        }

        return {
            EM: 'L·∫•y chi ti·∫øt b·ªô ƒë·ªÅ th√†nh c√¥ng!',
            EC: 0,
            DT: {
                id: questionBank.id,
                Ten: questionBank.Ten,
                Mota: questionBank.Mota,
                FileName: questionBank.FileName,
                FileType: questionBank.FileType,
                Metadata: questionBank.Metadata,
                items: questionBank.Items,
                createdAt: questionBank.createdAt
            }
        };
    } catch (error) {
        console.error('Error in getQuestionBankDetail:', error);
        return {
            EM: 'C√≥ l·ªói x·∫£y ra khi l·∫•y chi ti·∫øt b·ªô ƒë·ªÅ!',
            EC: -1,
            DT: null
        };
    }
};

/**
 * Get question bank items with filters (for selecting questions to add to test)
 */
const getQuestionBankItems = async (userId, filters = {}) => {
    try {
        const {
            bankId,
            chude,
            loaicauhoi,
            dodai,
            dokho,
            search,
            limit = 100,
            offset = 0
        } = filters;

        // Build where clause for QuestionBank
        const bankWhere = { userId };
        if (bankId) {
            bankWhere.id = bankId;
        }

        // Build where clause for QuestionBankItem
        const itemWhere = {};
        if (chude) {
            itemWhere.Chude = chude;
        }
        if (loaicauhoi) {
            itemWhere.Loaicauhoi = loaicauhoi;
        }
        if (dodai) {
            itemWhere.Dodai = dodai;
        }
        if (dokho) {
            itemWhere.Dokho = dokho;
        }
        if (search) {
            itemWhere[Op.or] = [
                { Cauhoi: { [Op.like]: `%${search}%` } },
                { Dapan: { [Op.like]: `%${search}%` } },
                { Chude: { [Op.like]: `%${search}%` } }
            ];
        }

        // Get question bank items
        const items = await db.QuestionBankItem.findAll({
            where: itemWhere,
            include: [{
                model: db.QuestionBank,
                as: 'QuestionBank',
                where: bankWhere,
                attributes: ['id', 'Ten', 'FileName']
            }],
            attributes: ['id', 'Cauhoi', 'Dapan', 'Chude', 'Loaicauhoi', 'Diem', 'Dodai', 'Dokho'],
            limit: parseInt(limit),
            offset: parseInt(offset),
            order: [['id', 'ASC']]
        });

        // Get total count for pagination
        const totalCount = await db.QuestionBankItem.count({
            where: itemWhere,
            include: [{
                model: db.QuestionBank,
                as: 'QuestionBank',
                where: bankWhere,
                attributes: []
            }]
        });

        // Get unique topics for filter options
        const allItems = await db.QuestionBankItem.findAll({
            where: {},
            include: [{
                model: db.QuestionBank,
                as: 'QuestionBank',
                where: { userId },
                attributes: []
            }],
            attributes: ['Chude', 'Loaicauhoi', 'Dodai', 'Dokho'],
            raw: true
        });

        const topics = [...new Set(allItems.map(i => i.Chude).filter(Boolean))].sort();
        const questionTypes = [...new Set(allItems.map(i => i.Loaicauhoi).filter(Boolean))].sort();
        const lengths = [...new Set(allItems.map(i => i.Dodai).filter(Boolean))].sort();
        const difficulties = [...new Set(allItems.map(i => i.Dokho).filter(Boolean))].sort();

        return {
            EM: 'L·∫•y danh s√°ch c√¢u h·ªèi th√†nh c√¥ng!',
            EC: 0,
            DT: {
                items: items,
                totalCount: totalCount,
                filters: {
                    topics,
                    questionTypes,
                    lengths,
                    difficulties
                }
            }
        };
    } catch (error) {
        console.error('Error in getQuestionBankItems:', error);
        return {
            EM: 'C√≥ l·ªói x·∫£y ra khi l·∫•y danh s√°ch c√¢u h·ªèi!',
            EC: -1,
            DT: null
        };
    }
};

/**
 * Delete question bank
 */
const deleteQuestionBank = async (userId, bankId) => {
    const transaction = await db.sequelize.transaction();
    
    try {
        const questionBank = await db.QuestionBank.findOne({
            where: {
                id: bankId,
                userId: userId
            },
            transaction
        });

        if (!questionBank) {
            await transaction.rollback();
            return {
                EM: 'Kh√¥ng t√¨m th·∫•y b·ªô ƒë·ªÅ!',
                EC: 1,
                DT: null
            };
        }

        // Delete file if exists
        if (questionBank.FilePath) {
            const filePath = path.resolve(__dirname, '..', 'public', questionBank.FilePath);
            if (fs.existsSync(filePath)) {
                try {
                    fs.unlinkSync(filePath);
                } catch (error) {
                    console.warn('Warning: Could not delete file:', error);
                }
            }
        }

        // Delete question bank (cascade will delete items)
        await questionBank.destroy({ transaction });

        await transaction.commit();

        return {
            EM: 'X√≥a b·ªô ƒë·ªÅ th√†nh c√¥ng!',
            EC: 0,
            DT: null
        };
    } catch (error) {
        await transaction.rollback();
        console.error('Error in deleteQuestionBank:', error);
        return {
            EM: 'C√≥ l·ªói x·∫£y ra khi x√≥a b·ªô ƒë·ªÅ!',
            EC: -1,
            DT: null
        };
    }
};

/**
 * Update question bank item (for HR to edit questions)
 */
const updateQuestionBankItem = async (userId, itemId, updateData) => {
    try {
        // First, verify the item belongs to a question bank owned by the user
        const item = await db.QuestionBankItem.findByPk(itemId, {
            include: [{
                model: db.QuestionBank,
                as: 'QuestionBank',
                attributes: ['id', 'userId']
            }]
        });

        if (!item) {
            return {
                EM: 'Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi!',
                EC: 1,
                DT: null
            };
        }

        if (!item.QuestionBank || item.QuestionBank.userId !== userId) {
            return {
                EM: 'B·∫°n kh√¥ng c√≥ quy·ªÅn ch·ªânh s·ª≠a c√¢u h·ªèi n√†y!',
                EC: 2,
                DT: null
            };
        }

        // Update the item
        await item.update({
            Cauhoi: updateData.Cauhoi || item.Cauhoi,
            Dapan: updateData.Dapan !== undefined ? updateData.Dapan : item.Dapan,
            Chude: updateData.Chude || item.Chude,
            Loaicauhoi: updateData.Loaicauhoi || item.Loaicauhoi,
            Diem: updateData.Diem !== undefined ? updateData.Diem : item.Diem,
            Dodai: updateData.Dodai || item.Dodai,
            Dokho: updateData.Dokho || item.Dokho,
            Metadata: {
                ...(item.Metadata || {}),
                editedAt: new Date().toISOString(),
                editedBy: userId
            }
        });

        return {
            EM: 'C·∫≠p nh·∫≠t c√¢u h·ªèi th√†nh c√¥ng!',
            EC: 0,
            DT: {
                id: item.id,
                Cauhoi: item.Cauhoi,
                Dapan: item.Dapan,
                Chude: item.Chude,
                Loaicauhoi: item.Loaicauhoi,
                Diem: item.Diem,
                Dodai: item.Dodai,
                Dokho: item.Dokho
            }
        };
    } catch (error) {
        console.error('Error in updateQuestionBankItem:', error);
        return {
            EM: 'C√≥ l·ªói x·∫£y ra khi c·∫≠p nh·∫≠t c√¢u h·ªèi!',
            EC: -1,
            DT: null
        };
    }
};

export default {
    uploadQuestionBank,
    getQuestionBanks,
    getQuestionBankDetail,
    deleteQuestionBank,
    updateQuestionBankItem,
    getQuestionBankItems
};

