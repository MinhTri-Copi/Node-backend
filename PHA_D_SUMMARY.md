# PHA D ‚Äì T√çCH H·ª¢P V√ÄO NODE + REACT + LLM SERVER

## ‚úÖ ƒê√É HO√ÄN TH√ÄNH

### B∆∞·ªõc D1 ‚Äì Node g·ªçi Fast Grading Service

**File:** `backend/src/service/fastGradingClient.js`

**Ch·ª©c nƒÉng:**
- `gradeWithFastModel(items)` - G·ªçi Python FastAPI service ƒë·ªÉ ch·∫•m b√†i
- `checkFastGradingHealth()` - Ki·ªÉm tra ML service c√≥ kh·∫£ d·ª•ng kh√¥ng

**C·∫•u h√¨nh:**
- `FAST_GRADING_URL` - URL c·ªßa Python service (m·∫∑c ƒë·ªãnh: `http://127.0.0.1:8000`)

### B∆∞·ªõc D2 ‚Äì S·ª≠a autoGradeSubmission trong Node

**File:** `backend/src/service/aiGradingService.js`

**Thay ƒë·ªïi:**
- Import `fastGradingClient`
- S·ª≠a `gradeAnswersBatch()` ƒë·ªÉ:
  1. Ki·ªÉm tra ML service c√≥ kh·∫£ d·ª•ng
  2. N·∫øu c√≥ ‚Üí d√πng ML model (nhanh)
  3. N·∫øu kh√¥ng ‚Üí fallback v·ªÅ LLM (ch·∫≠m h∆°n nh∆∞ng v·∫´n ho·∫°t ƒë·ªông)
- Th√™m h√†m `buildCommentFromScore()` ƒë·ªÉ t·∫°o comment t·ª´ ƒëi·ªÉm s·ªë

**Logic:**
```
1. NLP l·ªçc tr∆∞·ªõc (similarity >= 0.88) ‚Üí ch·∫•m b·∫±ng NLP
2. C√°c c√¢u c√≤n l·∫°i:
   - Ki·ªÉm tra ML service
   - N·∫øu c√≥ ‚Üí d√πng ML model (0.5-2s cho 10 c√¢u)
   - N·∫øu kh√¥ng ‚Üí d√πng LLM (20-30s cho 10 c√¢u)
```

### B∆∞·ªõc D3 ‚Äì Frontend React gi·ªØ nguy√™n

**Kh√¥ng c·∫ßn thay ƒë·ªïi:**
- V·∫´n g·ªçi `/api/test-submissions/:id/auto-grade`
- V·∫´n nh·∫≠n JSON results nh∆∞ hi·ªán t·∫°i
- UI hi·ªÉn th·ªã nh∆∞ c≈©

### B∆∞·ªõc D4 ‚Äì LLM server d√πng cho nh·∫≠n x√©t (Optional)

**H√†m:** `generateCommentWithLLM()` (ƒë√£ t·∫°o, ch∆∞a t√≠ch h·ª£p)

**C√°ch d√πng (n·∫øu mu·ªën):**
- Sau khi c√≥ ƒëi·ªÉm t·ª´ ML model
- G·ªçi LLM ƒë·ªÉ sinh nh·∫≠n x√©t "x·ªãn" h∆°n
- C√≥ th·ªÉ b·∫≠t/t·∫Øt qua config

## üìÅ C√ÅC FILE ƒê√É T·∫†O/C·∫¨P NH·∫¨T

1. **`backend/src/service/fastGradingClient.js`** (m·ªõi)
   - Client ƒë·ªÉ g·ªçi Python FastAPI service
   - Health check

2. **`backend/src/service/aiGradingService.js`** (ƒë√£ c·∫≠p nh·∫≠t)
   - T√≠ch h·ª£p ML model
   - Fallback v·ªÅ LLM n·∫øu ML kh√¥ng kh·∫£ d·ª•ng
   - H√†m `buildCommentFromScore()`
   - H√†m `generateCommentWithLLM()` (optional)

## üîÑ WORKFLOW

### 1. Ch·∫°y ML Service

```bash
cd ml-grader
python app.py
```

### 2. Ch·∫°y Node.js Backend

```bash
cd backend
npm start
```

### 3. Frontend g·ªçi API

```javascript
POST /api/test-submissions/:id/auto-grade
```

**Backend s·∫Ω:**
1. NLP l·ªçc c√°c c√¢u d·ªÖ (similarity >= 0.88)
2. G·ªçi ML model cho c√°c c√¢u c√≤n l·∫°i
3. N·∫øu ML kh√¥ng kh·∫£ d·ª•ng ‚Üí fallback LLM
4. Tr·∫£ v·ªÅ k·∫øt qu·∫£

## üìä SO S√ÅNH T·ªêC ƒê·ªò

| Ph∆∞∆°ng ph√°p | Th·ªùi gian (10 c√¢u) | ƒê·ªô ch√≠nh x√°c |
|------------|-------------------|--------------|
| **LLM (c≈©)** | 20-30s | Cao |
| **ML Model (m·ªõi)** | 0.5-2s | Trung b√¨nh-Cao |
| **NLP Filter** | < 0.1s | Trung b√¨nh |

## üéØ K·∫æT QU·∫¢

Sau khi ho√†n th√†nh PHA D:
- ‚úÖ Node.js backend t√≠ch h·ª£p ML service
- ‚úÖ T·ªëc ƒë·ªô ch·∫•m: **0.5-2s cho 10 c√¢u** (thay v√¨ 20-30s)
- ‚úÖ Fallback v·ªÅ LLM n·∫øu ML kh√¥ng kh·∫£ d·ª•ng
- ‚úÖ Frontend kh√¥ng c·∫ßn thay ƒë·ªïi
- ‚úÖ LLM ch·ªâ d√πng cho nh·∫≠n x√©t (optional)

## ‚öôÔ∏è C·∫§U H√åNH

**Environment variables:**
```env
# ML Grading Service URL
FAST_GRADING_URL=http://127.0.0.1:8000

# LLM Studio (fallback)
LM_STUDIO_URL=http://127.0.0.1:1234
LM_STUDIO_MODEL=qwen2.5-1.5b-instruct
```

## üêõ Troubleshooting

**L·ªói: Fast grading service kh√¥ng kh·∫£ d·ª•ng**
- Ki·ªÉm tra ML service ƒë√£ ch·∫°y ch∆∞a: `python ml-grader/app.py`
- Ki·ªÉm tra URL: `FAST_GRADING_URL` trong `.env`
- Backend s·∫Ω t·ª± ƒë·ªông fallback v·ªÅ LLM

**L·ªói: ML model tr·∫£ v·ªÅ k·∫øt qu·∫£ sai**
- Ki·ªÉm tra model ƒë√£ train ch∆∞a: `python ml-grader/train_grader.py`
- Ki·ªÉm tra d·ªØ li·ªáu training c√≥ ƒë·ªß kh√¥ng
- C√≥ th·ªÉ t·∫Øt ML model t·∫°m th·ªùi b·∫±ng c√°ch kh√¥ng ch·∫°y service

**T·ªëc ƒë·ªô v·∫´n ch·∫≠m:**
- Ki·ªÉm tra ML service c√≥ ƒëang ch·∫°y kh√¥ng
- Ki·ªÉm tra network latency
- Ki·ªÉm tra NLP filter c√≥ ho·∫°t ƒë·ªông kh√¥ng (n√™n l·ªçc ƒë∆∞·ª£c 30-50% c√¢u)

## üí° L∆ØU √ù

- **ML service ph·∫£i ch·∫°y tr∆∞·ªõc** khi backend kh·ªüi ƒë·ªông
- **Fallback t·ª± ƒë·ªông** n·∫øu ML kh√¥ng kh·∫£ d·ª•ng
- **Frontend kh√¥ng c·∫ßn thay ƒë·ªïi** - API response gi·ªØ nguy√™n format
- **LLM v·∫´n d√πng ƒë∆∞·ª£c** cho nh·∫≠n x√©t ƒë·∫πp (optional)

